{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.4 Model Comparison - OLS and KNN Regression\n",
    "You now know two kinds of regression and two kinds of classifier. So let's use that to compare models!\n",
    "\n",
    "Comparing models is something data scientists do all the time. There's very rarely just one model that would be possible to run for a given situation, so learning to choose the best one is very important.\n",
    "\n",
    "Here let's work on regression. Find a data set and build a KNN Regression and an OLS regression. Compare the two. How similar are they? Do they miss in different ways?\n",
    "\n",
    "Create a Jupyter notebook with your models. At the end in a markdown cell write a few paragraphs to describe the models' behaviors and why you favor one model or the other. Try to determine whether there is a situation where you would change your mind, or whether one is unambiguously better than the other. Lastly, try to note what it is about the data that causes the better model to outperform the weaker model. Submit a link to your notebook below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Exploration and Feature Selection\n",
    "For this challenge, I'll be using a wine quality data set obtained from\n",
    "https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "\n",
    "The objective is to predict **quality** based on select chemical parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect data\n",
    "df = pd.read_csv('winequality-red.csv', delimiter=';')\n",
    "df.head()\n",
    "df.columns = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sug', 'chlorides', 'free_sulf_diox', \n",
    "              'total_sulf_diox', 'density', 'pH', 'sulphates', 'alcohol', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sug</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulf_diox</th>\n",
       "      <th>total_sulf_diox</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed_acidity  volatile_acidity  citric_acid  residual_sug  \\\n",
       "count    1599.000000       1599.000000  1599.000000   1599.000000   \n",
       "mean        8.319637          0.527821     0.270976      2.538806   \n",
       "std         1.741096          0.179060     0.194801      1.409928   \n",
       "min         4.600000          0.120000     0.000000      0.900000   \n",
       "25%         7.100000          0.390000     0.090000      1.900000   \n",
       "50%         7.900000          0.520000     0.260000      2.200000   \n",
       "75%         9.200000          0.640000     0.420000      2.600000   \n",
       "max        15.900000          1.580000     1.000000     15.500000   \n",
       "\n",
       "         chlorides  free_sulf_diox  total_sulf_diox      density           pH  \\\n",
       "count  1599.000000     1599.000000      1599.000000  1599.000000  1599.000000   \n",
       "mean      0.087467       15.874922        46.467792     0.996747     3.311113   \n",
       "std       0.047065       10.460157        32.895324     0.001887     0.154386   \n",
       "min       0.012000        1.000000         6.000000     0.990070     2.740000   \n",
       "25%       0.070000        7.000000        22.000000     0.995600     3.210000   \n",
       "50%       0.079000       14.000000        38.000000     0.996750     3.310000   \n",
       "75%       0.090000       21.000000        62.000000     0.997835     3.400000   \n",
       "max       0.611000       72.000000       289.000000     1.003690     4.010000   \n",
       "\n",
       "         sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  \n",
       "mean      0.658149    10.422983     5.636023  \n",
       "std       0.169507     1.065668     0.807569  \n",
       "min       0.330000     8.400000     3.000000  \n",
       "25%       0.550000     9.500000     5.000000  \n",
       "50%       0.620000    10.200000     6.000000  \n",
       "75%       0.730000    11.100000     6.000000  \n",
       "max       2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  fixed_acidity  volatile_acidity  citric_acid  residual_sug  \\\n",
      "fixed_acidity          1.000000         -0.256131     0.671703      0.114777   \n",
      "volatile_acidity      -0.256131          1.000000    -0.552496      0.001918   \n",
      "citric_acid            0.671703         -0.552496     1.000000      0.143577   \n",
      "residual_sug           0.114777          0.001918     0.143577      1.000000   \n",
      "chlorides              0.093705          0.061298     0.203823      0.055610   \n",
      "free_sulf_diox        -0.153794         -0.010504    -0.060978      0.187049   \n",
      "total_sulf_diox       -0.113181          0.076470     0.035533      0.203028   \n",
      "density                0.668047          0.022026     0.364947      0.355283   \n",
      "pH                    -0.682978          0.234937    -0.541904     -0.085652   \n",
      "sulphates              0.183006         -0.260987     0.312770      0.005527   \n",
      "alcohol               -0.061668         -0.202288     0.109903      0.042075   \n",
      "quality                0.124052         -0.390558     0.226373      0.013732   \n",
      "\n",
      "                  chlorides  free_sulf_diox  total_sulf_diox   density  \\\n",
      "fixed_acidity      0.093705       -0.153794        -0.113181  0.668047   \n",
      "volatile_acidity   0.061298       -0.010504         0.076470  0.022026   \n",
      "citric_acid        0.203823       -0.060978         0.035533  0.364947   \n",
      "residual_sug       0.055610        0.187049         0.203028  0.355283   \n",
      "chlorides          1.000000        0.005562         0.047400  0.200632   \n",
      "free_sulf_diox     0.005562        1.000000         0.667666 -0.021946   \n",
      "total_sulf_diox    0.047400        0.667666         1.000000  0.071269   \n",
      "density            0.200632       -0.021946         0.071269  1.000000   \n",
      "pH                -0.265026        0.070377        -0.066495 -0.341699   \n",
      "sulphates          0.371260        0.051658         0.042947  0.148506   \n",
      "alcohol           -0.221141       -0.069408        -0.205654 -0.496180   \n",
      "quality           -0.128907       -0.050656        -0.185100 -0.174919   \n",
      "\n",
      "                        pH  sulphates   alcohol   quality  \n",
      "fixed_acidity    -0.682978   0.183006 -0.061668  0.124052  \n",
      "volatile_acidity  0.234937  -0.260987 -0.202288 -0.390558  \n",
      "citric_acid      -0.541904   0.312770  0.109903  0.226373  \n",
      "residual_sug     -0.085652   0.005527  0.042075  0.013732  \n",
      "chlorides        -0.265026   0.371260 -0.221141 -0.128907  \n",
      "free_sulf_diox    0.070377   0.051658 -0.069408 -0.050656  \n",
      "total_sulf_diox  -0.066495   0.042947 -0.205654 -0.185100  \n",
      "density          -0.341699   0.148506 -0.496180 -0.174919  \n",
      "pH                1.000000  -0.196648  0.205633 -0.057731  \n",
      "sulphates        -0.196648   1.000000  0.093595  0.251397  \n",
      "alcohol           0.205633   0.093595  1.000000  0.476166  \n",
      "quality          -0.057731   0.251397  0.476166  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Inspect variable correlation for feature selection\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the correlation matrix, I will select only features with a positive correlation >0.10 to the target variable 'quality'.  Choosing features with positive and negative correlations to the predicted value would lead to noise in the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               fixed_acidity  citric_acid  sulphates   alcohol   quality\n",
      "fixed_acidity       1.000000     0.671703   0.183006 -0.061668  0.124052\n",
      "citric_acid         0.671703     1.000000   0.312770  0.109903  0.226373\n",
      "sulphates           0.183006     0.312770   1.000000  0.093595  0.251397\n",
      "alcohol            -0.061668     0.109903   0.093595  1.000000  0.476166\n",
      "quality             0.124052     0.226373   0.251397  0.476166  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Define feature df\n",
    "data = df.loc[:, ['fixed_acidity', 'citric_acid', 'sulphates', 'alcohol', 'quality']]\n",
    "\n",
    "# Trimmed correlation matrix\n",
    "corr_matrix_data = data.corr()\n",
    "print(corr_matrix_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citric acid and fixed acidity are highly correlated.  To simplify model inputs, I'll remove fixed acidity because it has a weaker correlation to quality and therefore less predictive power.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             citric_acid  sulphates   alcohol   quality\n",
      "citric_acid     1.000000   0.312770  0.109903  0.226373\n",
      "sulphates       0.312770   1.000000  0.093595  0.251397\n",
      "alcohol         0.109903   0.093595  1.000000  0.476166\n",
      "quality         0.226373   0.251397  0.476166  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Modify feature df \n",
    "data = df.loc[:, ['citric_acid', 'sulphates', 'alcohol', 'quality']]\n",
    "\n",
    "# Trimmed correlation matrix\n",
    "corr_matrix_data = data.corr()\n",
    "print(corr_matrix_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12318190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect distribution of features\n",
    "# How do I make the grid layout taller? \n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, sharex=False, sharey=False)\n",
    "\n",
    "plt.plot(figsize=(20,20)) # doesn't appear to do anything\n",
    "\n",
    "ax1.hist(data['citric_acid'])\n",
    "ax1.set_title('citric acid')\n",
    "\n",
    "ax2.hist(data['sulphates'])\n",
    "ax2.set_title('sulphates')\n",
    "\n",
    "ax3.hist(data['alcohol'])\n",
    "ax3.set_title('alcohol')\n",
    "\n",
    "ax4.hist(data['quality'])\n",
    "ax4.set_title('quality')\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create train/test data sets for hold out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets (70/30)\n",
    "x = data.loc[:, ['citric_acid', 'sulphates', 'alcohol']]\n",
    "y = data.loc[:, ['quality']]\n",
    "\n",
    "# Split data using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. OLS Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression score - training data: 0.25415375300663634\n",
      "Regression score - test data: 0.33514429069401663\n"
     ]
    }
   ],
   "source": [
    "# Import linear model\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Instantiate and fit model with test data\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(x_train, y_train)\n",
    "\n",
    "# Get score for training data\n",
    "print('Regression score - training data:', lm.score(x_train, y_train))\n",
    "\n",
    "# Get score for test data\n",
    "print('Regression score - test data:', lm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not appear to be overfit; however, the model is not performing particularly well on either data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.254\n",
      "Model:                            OLS   Adj. R-squared:                  0.252\n",
      "Method:                 Least Squares   F-statistic:                     126.6\n",
      "Date:                Sat, 10 Mar 2018   Prob (F-statistic):           1.35e-70\n",
      "Time:                        16:38:38   Log-Likelihood:                -1165.2\n",
      "No. Observations:                1119   AIC:                             2338.\n",
      "Df Residuals:                    1115   BIC:                             2359.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       1.6651      0.213      7.819      0.000       1.247       2.083\n",
      "citric_acid     0.4661      0.112      4.179      0.000       0.247       0.685\n",
      "sulphates       0.7910      0.126      6.297      0.000       0.545       1.037\n",
      "alcohol         0.3178      0.020     16.007      0.000       0.279       0.357\n",
      "==============================================================================\n",
      "Omnibus:                       25.971   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.703\n",
      "Skew:                          -0.212   Prob(JB):                     2.39e-09\n",
      "Kurtosis:                       3.819   Cond. No.                         111.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Examine model parameters in greater depth using StatsModels\n",
    "\n",
    "# Import model\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Join x_train & y_train into one variable\n",
    "data = x_train.join(y_train)\n",
    "\n",
    "#specify interactions \n",
    "linear_formula = 'quality ~ citric_acid+sulphates+alcohol'\n",
    "\n",
    "# run validation\n",
    "lm = smf.ols(formula=linear_formula, data=data).fit()\n",
    "\n",
    "# get results\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS Summary\n",
    "Low R^2 values, indicating lots of unexplained variance in Y given X, although F-statistic reveals significant test and all parameters are significant (is F-test really all that valuable?). Poor model performance likely due to non-parametric distribution of predictors, poor feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. KNN Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9758861274563243\n",
      "Test: 0.05686269617505413\n"
     ]
    }
   ],
   "source": [
    "# ************************ K = 1 **********************************\n",
    "\n",
    "# Build model, fit with training data, set K=1, no weighting\n",
    "knn_1 = neighbors.KNeighborsRegressor(n_neighbors=1)\n",
    "knn_1.fit(x_train, y_train)\n",
    "\n",
    "print('Train:', knn_1.score(x_train, y_train))\n",
    "print('Test:', knn_1.score(x_test, y_test))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN_1 is overfit.  Performance on test data is much worse than training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.5062046288291533\n",
      "Test: 0.31926445270590564\n"
     ]
    }
   ],
   "source": [
    "# ************************** K = 5 ********************************\n",
    "\n",
    "# Build model, K=5, no weighting\n",
    "knn_5 = neighbors.KNeighborsRegressor(n_neighbors=5)\n",
    "knn_5.fit(x_train, y_train)\n",
    "\n",
    "print('Train:', knn_5.score(x_train, y_train))\n",
    "print('Test:', knn_5.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN_5 is less overfit than KNN_1, however, the model still exhibits overfitting and does not perform that well.  This version of the model performs roughly the same as the OLS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9881794742432961\n",
      "Test: 0.37550577922385764\n"
     ]
    }
   ],
   "source": [
    "# *********************** K = 5, Distance Weighted *************************\n",
    "\n",
    "# Build model, K=5, weighting\n",
    "knn_5w = neighbors.KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "knn_5w.fit(x_train, y_train)\n",
    "\n",
    "print('Train:', knn_5w.score(x_train, y_train))\n",
    "print('Test:', knn_5w.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs quite well on the training data set, but still shows overfitting.  Despite the overfitting, this is the best version of the model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "In general, all models perform poorly indicating better feature selection could be done.  The features should also be normalized due to their varying scales.  The OLS model is less prone to overfitting than KNN Regression.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "If doing data transformation - does it happen before testing any models or do you incorporate/customize it for each individual model (i.e. transform to normal distribution for linear model, but not KNN, and normalize for KNN but not OLS)?  At what point do you untransform it?  Do you need to worry about undoing the transform in order to determine the model score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
