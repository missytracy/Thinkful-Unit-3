{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.4 Logistic Regression\n",
    "\n",
    "**Task**<br>\n",
    "Now that you have two new regression methods at your fingertips, it's time to give them a spin. In fact, for this challenge, let's put them together! Pick a dataset of your choice with a binary outcome and the potential for at least 15 features. If you're drawing a blank, the crime rates in 2013 dataset has a lot of variables that could be made into a modelable binary outcome.\n",
    "\n",
    "Engineer your features, then create three models. Each model will be run on a training set and a test-set (or multiple test-sets, if you take a folds approach). The models should be:\n",
    "\n",
    "* Vanilla logistic regression\n",
    "* Ridge logistic regression\n",
    "* Lasso logistic regression\n",
    "\n",
    "In your report, evaluate all three models and decide on your best. Be clear about the decisions you made that led to these models (feature selection, regularization parameter selection, model evaluation criteria) and why you think that particular model is the best of the three. Also reflect on the strengths and limitations of regression as a modeling approach. Were there things you couldn't do but you wish you could have done?\n",
    "\n",
    "**Data**<br>\n",
    "Predicting credit card fraud.\n",
    "\n",
    "Data Source: https://www.kaggle.com/mlg-ulb/creditcardfraud/data\n",
    "\n",
    "Data has been anonymized through PCA.  The results are 28 principle components, a time variable, transaction amount, and classification as fraud (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in data\n",
    "df = pd.read_csv('creditcardfraud.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient\n",
      "[[-7.12205661e-05  3.19001931e-01 -4.84125628e-01 -7.93512825e-01\n",
      "   1.20293566e-01  5.74886414e-02 -5.40509683e-02  3.35307692e-01\n",
      "  -3.74349559e-01 -3.88608914e-01 -2.07048719e-01 -2.86743952e-01\n",
      "   1.86455372e-02 -3.06674966e-01 -6.94622189e-01 -4.27799496e-01\n",
      "  -2.94742322e-01 -4.39989190e-01  3.10683059e-02  2.65188972e-02\n",
      "   9.20024094e-02  2.48887616e-01  3.51030078e-01  6.77173252e-02\n",
      "  -2.44442971e-02 -3.56185269e-01  6.07207628e-02 -8.88572729e-02\n",
      "   2.77995748e-02 -5.58259375e-03]]\n",
      "[-1.62885062]\n",
      "\n",
      "Accuracy by fraud status\n",
      "Class       0    1\n",
      "row_0             \n",
      "0      284240  203\n",
      "1          75  289\n",
      "\n",
      "Percentage accuracy\n",
      "0.9990239003957065\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate and set regularization coefficient to large value\n",
    "lr = LogisticRegression(C=1e9)\n",
    "\n",
    "# Define variables\n",
    "x = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Fit model\n",
    "fit = lr.fit(x, y)\n",
    "\n",
    "# Get results\n",
    "print('Coefficient')\n",
    "coef = fit.coef_\n",
    "print(coef)\n",
    "print(fit.intercept_)\n",
    "\n",
    "# Get predictions\n",
    "pred_y = lr.predict(x)\n",
    "\n",
    "print('\\nAccuracy by fraud status')\n",
    "print(pd.crosstab(pred_y, y))\n",
    "\n",
    "print('\\nPercentage accuracy')\n",
    "print(lr.score(x,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* large class imbalance leading to very high accuracy \n",
    "* 203 fraudulent cases mislabeled as not fraud\n",
    "* 75 miscategorized as fraud "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Logistic Regression\n",
    "L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate range of alpha values to pick one resulting in best r squared\n",
    "alphas = np.arange(0.1, 10, 1)\n",
    "lr_ridge = LogisticRegression(penalty='l2')\n",
    "ridge_r_squared = []\n",
    "\n",
    "# Train model with different regularization values\n",
    "for a in alphas:\n",
    "    lr_ridge.set_params(C=a, fit_intercept=False)\n",
    "    lr_ridge.fit(x, y)\n",
    "    y_pred = lr_ridge.predict(x)\n",
    "    ridge_r_squared.append(lr_ridge.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9984831833487239,\n",
       " 0.9985393617432156,\n",
       " 0.9985253171445927,\n",
       " 0.9985253171445927,\n",
       " 0.9986271404846089,\n",
       " 0.9985218059949369,\n",
       " 0.9985218059949369,\n",
       " 0.9985218059949369,\n",
       " 0.9985218059949369,\n",
       " 0.9985218059949369]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get values\n",
    "ridge_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get alpha corresponding to highest r-squared\n",
    "alphas[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient\n",
      "[[-1.00363009e-04  4.95539317e-01 -8.64729681e-01 -1.41665871e+00\n",
      "   2.11182323e-01 -1.48737343e-01 -2.81149840e-02  7.70208490e-01\n",
      "  -4.84613149e-01 -5.64425923e-01 -4.41858733e-01 -5.07158083e-01\n",
      "  -4.80217284e-02 -3.81347402e-01 -6.59168776e-01 -9.39193951e-01\n",
      "  -4.37884633e-01 -6.15370299e-01  1.57018671e-01 -5.82967583e-02\n",
      "   5.13752137e-01  6.88499318e-01  8.80571737e-01  3.58571084e-01\n",
      "   2.03330059e-02 -1.15529186e+00  2.83262888e-01 -1.99524115e-01\n",
      "   8.88575969e-02 -1.24274188e-02]]\n",
      "0.0\n",
      "\n",
      "Accuracy by fraud status\n",
      "Class       0    1\n",
      "row_0             \n",
      "0      284113  189\n",
      "1         202  303\n",
      "\n",
      "Percentage accuracy\n",
      "0.9986271404846089\n"
     ]
    }
   ],
   "source": [
    "# Not much variation observed by changing penalization coefficient.  Select best one.\n",
    "\n",
    "# Instantiate and set regularization coefficient \n",
    "lr_ridge = LogisticRegression(penalty='l2', C=4.1, fit_intercept=False)\n",
    "\n",
    "# Fit model\n",
    "lr_ridge.fit(x, y)\n",
    "\n",
    "# Get results\n",
    "print('Coefficient')\n",
    "print(lr_ridge.coef_)\n",
    "print(lr_ridge.intercept_)\n",
    "\n",
    "# Get predictions\n",
    "pred_y_r = lr_ridge.predict(x)\n",
    "\n",
    "print('\\nAccuracy by fraud status')\n",
    "print(pd.crosstab(pred_y_r, y))\n",
    "\n",
    "print('\\nPercentage accuracy')\n",
    "print(lr_ridge.score(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overall accuracy actually went down\n",
    "* Improved classification of fraud (what we're really after) at the expense of increased false positives\n",
    "* Not expected results.  Could it be due to data already having PCA analysis conducted?  Or how penalization coefficient is being determined?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Logistic Regression\n",
    "\n",
    "L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat iterative process to find best value of penalization coefficient\n",
    "\n",
    "# Generate range of alpha values\n",
    "alphas = np.arange(0.01, 1, 0.1)\n",
    "lr_lasso = LogisticRegression(penalty='l1')\n",
    "lasso_r_squared = []\n",
    "\n",
    "# Train model with different regularization values\n",
    "for a in alphas:\n",
    "    lr_lasso.set_params(C=a, fit_intercept=False)\n",
    "    lr_lasso.fit(x, y)\n",
    "    y_pred = lr_lasso.predict(x)\n",
    "    lasso_r_squared.append(lr_lasso.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9984902056480354,\n",
       " 0.9988202537156742,\n",
       " 0.9988413206136085,\n",
       " 0.9988448317632642,\n",
       " 0.9988378094639527,\n",
       " 0.9988378094639527,\n",
       " 0.9988413206136085,\n",
       " 0.9988413206136085,\n",
       " 0.9988448317632642,\n",
       " 0.9988448317632642]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get values\n",
    "lasso_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient\n",
      "[[-1.52403584e-05  0.00000000e+00  0.00000000e+00 -2.56184060e-02\n",
      "   2.85757773e-01  4.21347000e-02  0.00000000e+00  0.00000000e+00\n",
      "  -1.34171116e-01 -1.15931038e-02 -2.83624536e-01  0.00000000e+00\n",
      "  -6.93929718e-02  0.00000000e+00 -7.00286781e-01  0.00000000e+00\n",
      "  -3.27052109e-02 -1.02405851e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.13878307e-04]]\n",
      "[-6.03523999]\n",
      "\n",
      "Accuracy by fraud status\n",
      "Class       0    1\n",
      "row_0             \n",
      "0      284278  211\n",
      "1          37  281\n",
      "\n",
      "Percentage accuracy\n",
      "0.9991292348853785\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and set regularization coefficient to selected value\n",
    "lr_lasso = LogisticRegression(penalty='l1', C=0.01)\n",
    "\n",
    "# Fit model\n",
    "lr_lasso.fit(x, y)\n",
    "\n",
    "# Get results\n",
    "print('Coefficient')\n",
    "print(lr_lasso.coef_)\n",
    "print(lr_lasso.intercept_)\n",
    "\n",
    "# Get predictions\n",
    "pred_y_l = lr_lasso.predict(x)\n",
    "\n",
    "print('\\nAccuracy by fraud status')\n",
    "print(pd.crosstab(pred_y_l, y))\n",
    "\n",
    "print('\\nPercentage accuracy')\n",
    "print(lr_lasso.score(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ This r squared doesn't match up with iteration results\n",
    "* Overall accuracy improved, but false negatives increased.  Overall worst performance considering goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "Strenths and limitations:\n",
    "* **Ridge regression** keeps all predictor variables.  Good if you they're all relevant for predicting target variable.  Otherwise, makes model more complicated than it needs to be.\n",
    "* **LASSO regression** performs feature selection, which reduces model complexity.  Undesireable if you want to keep all features in model.\n",
    "\n",
    "Data set specifics:\n",
    "* Ridge and LASSO did not produce substantially better results than the regular logistic regression.  Is this because of the data structure and how it was preprocessed already?  Or is it something with hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
